{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KCW-aNk3uGB",
        "outputId": "6e4bb762-9533-47eb-848a-19c1442f124e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "sU8z0vBB3x3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"Practice2\").getOrCreate() #starting the session"
      ],
      "metadata": {
        "id": "eOOknBzz39dy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "4Bg_RhKq4mRA",
        "outputId": "de39c334-7312-423c-ec48-e942feb7c614"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7d031f4bfb50>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://6c87b17506bf:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Practice2</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading the dataset #Method1"
      ],
      "metadata": {
        "id": "qUOMEADe4uaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark = spark.read.option('header','true').csv('test1.csv')"
      ],
      "metadata": {
        "id": "TUsfLLdM4s-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the schema"
      ],
      "metadata": {
        "id": "62d6pFBP7Teb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.printSchema()  #checking the datatype of the column"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RosoZdka4wTO",
        "outputId": "6c1305ec-053a-456a-a89e-22526194e9da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- age: string (nullable = true)\n",
            " |-- Experience: string (nullable = true)\n",
            " |-- Salary: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above code displays even the columns \"age\" & \"salary\" to be of String type. Let's try to improve this:"
      ],
      "metadata": {
        "id": "S_6o8YZw7d_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark = spark.read.option('header', 'true').csv('test1.csv', inferSchema = True)  #if we don't add inferSchema, by default it will consider all the features as string values"
      ],
      "metadata": {
        "id": "KwjvTm1_7p1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGeE2yEK8XqG",
        "outputId": "efaae940-2b4c-43ad-b246-f3cbedbff4be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- Experience: integer (nullable = true)\n",
            " |-- Salary: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading the dataset #Method2 - including both header and inferSchema"
      ],
      "metadata": {
        "id": "ZJD60lbl8Pde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark = spark.read.csv('test1.csv', header=True, inferSchema = True)"
      ],
      "metadata": {
        "id": "OCRcd59S-58q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXYXho6J_WOU",
        "outputId": "7627ad4b-032f-41d3-edba-1ce5420a2a70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+----------+------+\n",
            "|   Name|age|Experience|Salary|\n",
            "+-------+---+----------+------+\n",
            "| Shivam| 31|        10| 30000|\n",
            "|  Aashi| 30|         8| 25000|\n",
            "| Monica| 29|         4| 20000|\n",
            "|   Paul| 24|         3| 20000|\n",
            "|Karnika| 21|         1| 15000|\n",
            "|Shubham| 23|         2| 18000|\n",
            "+-------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrvgUy3S_bRG",
        "outputId": "0a957232-902a-412c-e0ac-d087690435b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- Experience: integer (nullable = true)\n",
            " |-- Salary: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(df_pyspark)  #a dataframe is a data structure inside which we can perform various operations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "id": "Y-488zY7_hEl",
        "outputId": "03aa71e4-88e9-420a-b5c8-241d5335bc60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.sql.dataframe.DataFrame</b><br/>def __init__(jdf: JavaObject, sql_ctx: Union[&#x27;SQLContext&#x27;, &#x27;SparkSession&#x27;])</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/pyspark/sql/dataframe.py</a>A distributed collection of data grouped into named columns.\n",
              "\n",
              ".. versionadded:: 1.3.0\n",
              "\n",
              ".. versionchanged:: 3.4.0\n",
              "    Supports Spark Connect.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "A :class:`DataFrame` is equivalent to a relational table in Spark SQL,\n",
              "and can be created using various functions in :class:`SparkSession`:\n",
              "\n",
              "&gt;&gt;&gt; people = spark.createDataFrame([\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 40, &quot;name&quot;: &quot;Hyukjin Kwon&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 50},\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 50, &quot;name&quot;: &quot;Takuya Ueshin&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 100},\n",
              "...     {&quot;deptId&quot;: 2, &quot;age&quot;: 60, &quot;name&quot;: &quot;Xinrong Meng&quot;, &quot;gender&quot;: &quot;F&quot;, &quot;salary&quot;: 150},\n",
              "...     {&quot;deptId&quot;: 3, &quot;age&quot;: 20, &quot;name&quot;: &quot;Haejoon Lee&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 200}\n",
              "... ])\n",
              "\n",
              "Once created, it can be manipulated using the various domain-specific-language\n",
              "(DSL) functions defined in: :class:`DataFrame`, :class:`Column`.\n",
              "\n",
              "To select a column from the :class:`DataFrame`, use the apply method:\n",
              "\n",
              "&gt;&gt;&gt; age_col = people.age\n",
              "\n",
              "A more concrete example:\n",
              "\n",
              "&gt;&gt;&gt; # To create DataFrame using SparkSession\n",
              "... department = spark.createDataFrame([\n",
              "...     {&quot;id&quot;: 1, &quot;name&quot;: &quot;PySpark&quot;},\n",
              "...     {&quot;id&quot;: 2, &quot;name&quot;: &quot;ML&quot;},\n",
              "...     {&quot;id&quot;: 3, &quot;name&quot;: &quot;Spark SQL&quot;}\n",
              "... ])\n",
              "\n",
              "&gt;&gt;&gt; people.filter(people.age &gt; 30).join(\n",
              "...     department, people.deptId == department.id).groupBy(\n",
              "...     department.name, &quot;gender&quot;).agg({&quot;salary&quot;: &quot;avg&quot;, &quot;age&quot;: &quot;max&quot;}).show()\n",
              "+-------+------+-----------+--------+\n",
              "|   name|gender|avg(salary)|max(age)|\n",
              "+-------+------+-----------+--------+\n",
              "|     ML|     F|      150.0|      60|\n",
              "|PySpark|     M|       75.0|      50|\n",
              "+-------+------+-----------+--------+\n",
              "\n",
              "Notes\n",
              "-----\n",
              "A DataFrame should only be created as described above. It should not be directly\n",
              "created via using the constructor.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 80);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting all column names"
      ],
      "metadata": {
        "id": "gS8nMN8bAD2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyNusncEAF9D",
        "outputId": "d2cddf83-4cfc-4ae7-d01e-1b7bce2282a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Name', 'age', 'Experience', 'Salary']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting some head elements + column names"
      ],
      "metadata": {
        "id": "DKXtBWcuAOvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.head(2)  #getting o/p in a list format"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qb8fxQOmARVW",
        "outputId": "115f4fa0-e13a-439e-f0ab-f27377bf83f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Name='Shivam', age=31, Experience=10, Salary=30000),\n",
              " Row(Name='Aashi', age=30, Experience=8, Salary=25000)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selecting/picking up a column #Method1"
      ],
      "metadata": {
        "id": "a22APVXpAZcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.select('Name') #selecting the 'Name' column"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGr4XCh0Afgu",
        "outputId": "a8334622-4c39-4f73-d6aa-2d8afdb8d7ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[Name: string]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above example, return type is dataframe. Let's use show() to view the entire column"
      ],
      "metadata": {
        "id": "CG2UAOgnApjx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.select('Name').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cn1SWfvUBEEg",
        "outputId": "f2bcdbf9-8d9f-47f3-ce49-2d7a98cd0784"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+\n",
            "|   Name|\n",
            "+-------+\n",
            "| Shivam|\n",
            "|  Aashi|\n",
            "| Monica|\n",
            "|   Paul|\n",
            "|Karnika|\n",
            "|Shubham|\n",
            "+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the type of the dataframe"
      ],
      "metadata": {
        "id": "N-Rq-bHZBbES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(df_pyspark.select('Name'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "P0fDcLHFBenr",
        "outputId": "4ca12442-a541-4407-aa96-a536bd0755e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.sql.dataframe.DataFrame</b><br/>def __init__(jdf: JavaObject, sql_ctx: Union[&#x27;SQLContext&#x27;, &#x27;SparkSession&#x27;])</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/pyspark/sql/dataframe.py</a>A distributed collection of data grouped into named columns.\n",
              "\n",
              ".. versionadded:: 1.3.0\n",
              "\n",
              ".. versionchanged:: 3.4.0\n",
              "    Supports Spark Connect.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "A :class:`DataFrame` is equivalent to a relational table in Spark SQL,\n",
              "and can be created using various functions in :class:`SparkSession`:\n",
              "\n",
              "&gt;&gt;&gt; people = spark.createDataFrame([\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 40, &quot;name&quot;: &quot;Hyukjin Kwon&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 50},\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 50, &quot;name&quot;: &quot;Takuya Ueshin&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 100},\n",
              "...     {&quot;deptId&quot;: 2, &quot;age&quot;: 60, &quot;name&quot;: &quot;Xinrong Meng&quot;, &quot;gender&quot;: &quot;F&quot;, &quot;salary&quot;: 150},\n",
              "...     {&quot;deptId&quot;: 3, &quot;age&quot;: 20, &quot;name&quot;: &quot;Haejoon Lee&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 200}\n",
              "... ])\n",
              "\n",
              "Once created, it can be manipulated using the various domain-specific-language\n",
              "(DSL) functions defined in: :class:`DataFrame`, :class:`Column`.\n",
              "\n",
              "To select a column from the :class:`DataFrame`, use the apply method:\n",
              "\n",
              "&gt;&gt;&gt; age_col = people.age\n",
              "\n",
              "A more concrete example:\n",
              "\n",
              "&gt;&gt;&gt; # To create DataFrame using SparkSession\n",
              "... department = spark.createDataFrame([\n",
              "...     {&quot;id&quot;: 1, &quot;name&quot;: &quot;PySpark&quot;},\n",
              "...     {&quot;id&quot;: 2, &quot;name&quot;: &quot;ML&quot;},\n",
              "...     {&quot;id&quot;: 3, &quot;name&quot;: &quot;Spark SQL&quot;}\n",
              "... ])\n",
              "\n",
              "&gt;&gt;&gt; people.filter(people.age &gt; 30).join(\n",
              "...     department, people.deptId == department.id).groupBy(\n",
              "...     department.name, &quot;gender&quot;).agg({&quot;salary&quot;: &quot;avg&quot;, &quot;age&quot;: &quot;max&quot;}).show()\n",
              "+-------+------+-----------+--------+\n",
              "|   name|gender|avg(salary)|max(age)|\n",
              "+-------+------+-----------+--------+\n",
              "|     ML|     F|      150.0|      60|\n",
              "|PySpark|     M|       75.0|      50|\n",
              "+-------+------+-----------+--------+\n",
              "\n",
              "Notes\n",
              "-----\n",
              "A DataFrame should only be created as described above. It should not be directly\n",
              "created via using the constructor.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 80);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selecting 2 columns"
      ],
      "metadata": {
        "id": "1cfKIIEZBm3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.select(['Name', 'Experience'])   #getting the dataframe with 2 features in o/p"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIrC-5a-Bo5-",
        "outputId": "7e1631df-0a8b-4462-aa32-c83d460b97a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[Name: string, Experience: int]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.select(['Name', 'Experience']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neNKV_-fB0Eb",
        "outputId": "f097da53-633d-443b-e89b-67472903025a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+\n",
            "|   Name|Experience|\n",
            "+-------+----------+\n",
            "| Shivam|        10|\n",
            "|  Aashi|         8|\n",
            "| Monica|         4|\n",
            "|   Paul|         3|\n",
            "|Karnika|         1|\n",
            "|Shubham|         2|\n",
            "+-------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selecting columns #Method2"
      ],
      "metadata": {
        "id": "wiMAoEW3CFnf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark['Name']  #directly picking, getting not much info in o/p"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUWxEpb7CICw",
        "outputId": "a36db5eb-0335-4e89-b172-25265132eac9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Column<'Name'>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the datatypes of columns"
      ],
      "metadata": {
        "id": "6xnu6U2pCWlm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEr5OmxmCYuO",
        "outputId": "7ab1659b-ecab-4dd4-82b1-8c5486a7a2f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Name', 'string'), ('age', 'int'), ('Experience', 'int'), ('Salary', 'int')]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the describe option similar to pandas"
      ],
      "metadata": {
        "id": "LRf8ViZ4CkBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.describe()   #will give dataframe summary in o/p"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vta-P4bxCs26",
        "outputId": "1b774487-ed30-4b1a-ad6e-cf00eb6d5b06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[summary: string, Name: string, age: string, Experience: string, Salary: string]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "using show() with describe()"
      ],
      "metadata": {
        "id": "QWdvfYS8C0G-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qg78b4eJC3UE",
        "outputId": "ade9be4a-d52d-4c40-b800-71eac45c53f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+------------------+-----------------+------------------+\n",
            "|summary|   Name|               age|       Experience|            Salary|\n",
            "+-------+-------+------------------+-----------------+------------------+\n",
            "|  count|      6|                 6|                6|                 6|\n",
            "|   mean|   NULL|26.333333333333332|4.666666666666667|21333.333333333332|\n",
            "| stddev|   NULL| 4.179314138308661|3.559026084010437| 5354.126134736337|\n",
            "|    min|  Aashi|                21|                1|             15000|\n",
            "|    max|Shubham|                31|               10|             30000|\n",
            "+-------+-------+------------------+-----------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding columns in dataframe"
      ],
      "metadata": {
        "id": "v4wdqDLYDFnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.withColumn('Experience After 2 years', df_pyspark['Experience'] + 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "305PO_O-DMk8",
        "outputId": "bde4dd9c-7e25-4ac5-e1a4-453403d6ae85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[Name: string, age: int, Experience: int, Salary: int, Experience After 2 years: int]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.withColumn('Experience After 2 years', df_pyspark['Experience'] + 2).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZAGExIFDlL5",
        "outputId": "d3a81ec6-51a5-4a9d-f9f3-b5800de9f1d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+----------+------+------------------------+\n",
            "|   Name|age|Experience|Salary|Experience After 2 years|\n",
            "+-------+---+----------+------+------------------------+\n",
            "| Shivam| 31|        10| 30000|                      12|\n",
            "|  Aashi| 30|         8| 25000|                      10|\n",
            "| Monica| 29|         4| 20000|                       6|\n",
            "|   Paul| 24|         3| 20000|                       5|\n",
            "|Karnika| 21|         1| 15000|                       3|\n",
            "|Shubham| 23|         2| 18000|                       4|\n",
            "+-------+---+----------+------+------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drop columns from the dataframe"
      ],
      "metadata": {
        "id": "HRo0a9GYD5o7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.drop('age')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaS5ckSjD8ZL",
        "outputId": "e5061db9-a7cf-4fb1-eb59-549b7acb8614"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[Name: string, Experience: int, Salary: int]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.drop('age').show()   #dropped the 'age' column"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMDKEU3BEBoT",
        "outputId": "08d73379-8abb-41d3-9f08-bd3b498533cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+------+\n",
            "|   Name|Experience|Salary|\n",
            "+-------+----------+------+\n",
            "| Shivam|        10| 30000|\n",
            "|  Aashi|         8| 25000|\n",
            "| Monica|         4| 20000|\n",
            "|   Paul|         3| 20000|\n",
            "|Karnika|         1| 15000|\n",
            "|Shubham|         2| 18000|\n",
            "+-------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Renaming the column"
      ],
      "metadata": {
        "id": "1ISKZMOSEJrF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.withColumnRenamed('Name', 'New Name')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BR8TJ16hELHC",
        "outputId": "fa9f8ae7-0c1d-4912-f361-c5a8c9c1ec9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[New Name: string, age: int, Experience: int, Salary: int]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.withColumnRenamed('Name', 'New Name').show()   #renamed column 'Name' to 'New Name'"
      ],
      "metadata": {
        "id": "mdW283NGEa17",
        "outputId": "0f2d90ef-d49f-416a-ca52-0d9e20efd14a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---+----------+------+\n",
            "|New Name|age|Experience|Salary|\n",
            "+--------+---+----------+------+\n",
            "|  Shivam| 31|        10| 30000|\n",
            "|   Aashi| 30|         8| 25000|\n",
            "|  Monica| 29|         4| 20000|\n",
            "|    Paul| 24|         3| 20000|\n",
            "| Karnika| 21|         1| 15000|\n",
            "| Shubham| 23|         2| 18000|\n",
            "+--------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}