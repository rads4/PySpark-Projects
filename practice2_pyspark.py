# -*- coding: utf-8 -*-
"""Practice2_PySpark.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tb8fExcHTlI98OyTKafuPPhJ2mhNnWKg
"""

!pip install pyspark

import pyspark
from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("Practice2").getOrCreate() #starting the session

spark

"""Reading the dataset #Method1"""

df_pyspark = spark.read.option('header','true').csv('test1.csv')

"""Checking the schema"""

df_pyspark.printSchema()  #checking the datatype of the column

"""The above code displays even the columns "age" & "salary" to be of String type. Let's try to improve this:"""

df_pyspark = spark.read.option('header', 'true').csv('test1.csv', inferSchema = True)  #if we don't add inferSchema, by default it will consider all the features as string values

df_pyspark.printSchema()

"""Reading the dataset #Method2 - including both header and inferSchema"""

df_pyspark = spark.read.csv('test1.csv', header=True, inferSchema = True)

df_pyspark.show()

df_pyspark.printSchema()

type(df_pyspark)  #a dataframe is a data structure inside which we can perform various operations

"""Getting all column names"""

df_pyspark.columns

"""Getting some head elements + column names"""

df_pyspark.head(2)  #getting o/p in a list format

"""Selecting/picking up a column #Method1"""

df_pyspark.select('Name') #selecting the 'Name' column

"""In the above example, return type is dataframe. Let's use show() to view the entire column"""

df_pyspark.select('Name').show()

"""Checking the type of the dataframe"""

type(df_pyspark.select('Name'))

"""Selecting 2 columns"""

df_pyspark.select(['Name', 'Experience'])   #getting the dataframe with 2 features in o/p

df_pyspark.select(['Name', 'Experience']).show()

"""Selecting columns #Method2"""

df_pyspark['Name']  #directly picking, getting not much info in o/p

"""Checking the datatypes of columns"""

df_pyspark.dtypes

"""Check the describe option similar to pandas"""

df_pyspark.describe()   #will give dataframe summary in o/p

"""using show() with describe()"""

df_pyspark.describe().show()

"""Adding columns in dataframe"""

df_pyspark.withColumn('Experience After 2 years', df_pyspark['Experience'] + 2)

df_pyspark.withColumn('Experience After 2 years', df_pyspark['Experience'] + 2).show()

"""Drop columns from the dataframe"""

df_pyspark.drop('age')

df_pyspark.drop('age').show()   #dropped the 'age' column

"""Renaming the column"""

df_pyspark.withColumnRenamed('Name', 'New Name')

df_pyspark.withColumnRenamed('Name', 'New Name').show()   #renamed column 'Name' to 'New Name'